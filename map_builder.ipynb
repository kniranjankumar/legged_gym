{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2map_coordinates(x, y, scale,origin):\n",
    "    return (x*scale+origin[0], y*scale+origin[1])\n",
    "\n",
    "def convert2world_coordinates(x, y, scale,origin):\n",
    "    return (x-origin[0])//scale, (y-origin[1])//scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 2000\n",
    "scale = 50\n",
    "origin = [image_size//2, image_size//2]\n",
    "map = np.zeros([image_size, image_size], dtype=np.uint8)\n",
    "low = [-3, -4]\n",
    "high = [3, 2]\n",
    "low_map = convert2map_coordinates(low[0], low[1], scale, origin)\n",
    "high_map = convert2map_coordinates(high[0], high[1], scale, origin)\n",
    "map[low_map[1]:high_map[1], low_map[0]:high_map[0]] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('single_room_map.png', map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(map, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb4a666c950>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "test_image = torch.zeros([512,512])\n",
    "test_image[100:200,100:200] = 1\n",
    "plt.imshow(test_image.numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rot_mat(theta):\n",
    "    theta = torch.tensor(theta)\n",
    "    return torch.tensor([[torch.cos(theta), -torch.sin(theta), 0],\n",
    "                         [torch.sin(theta), torch.cos(theta), 0]])\n",
    "\n",
    "\n",
    "def rot_img(x, theta, dtype):\n",
    "    rot_mat = get_rot_mat(theta)[None, ...].type(dtype).repeat(x.shape[0],1,1)\n",
    "    grid = F.affine_grid(rot_mat, x.size()).type(dtype)\n",
    "    x = F.grid_sample(x, grid)\n",
    "    return x\n",
    "\n",
    "\n",
    "theta = torch.rand(10)*np.pi/2\n",
    "rot_mat = get_batch_rot_mat(theta)\n",
    "grid = F.affine_grid(rot_mat, test_image.view(-1,1,512,512).size()).type(dtype)\n",
    "x = F.grid_sample(x, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_image = rot_img(test_image.view(1,1,512,512), np.pi/4, torch.float32)\n",
    "plt.imshow(rotated_image.squeeze(0).permute(1,2,0)/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = TF.rotate(test_image.view(1,1,512,512), 30)\n",
    "plt.imshow(out.squeeze(0).permute(1,2,0)/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_rot_mat(theta):\n",
    "    cos_theta = torch.cos(theta)\n",
    "    sin_theta = torch.sin(theta)\n",
    "    return torch.stack([cos_theta, -sin_theta, torch.zeros_like(sin_theta)+0.25, sin_theta, cos_theta, torch.zeros_like(sin_theta)+0.25], dim=1).reshape(-1,2,3)#.permute(0,2,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niranjan/anaconda3/envs/rlgpu/lib/python3.7/site-packages/torch/nn/functional.py:4066: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.68 GiB (GPU 0; 11.90 GiB total capacity; 5.37 GiB already allocated; 1.32 GiB free; 5.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1307/474453326.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mrot_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_pos_y\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mrot_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_pos_x\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrot_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlgpu/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36maffine_grid\u001b[0;34m(theta, size, align_corners)\u001b[0m\n\u001b[1;32m   4106\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected non-zero, positive output size. Got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine_grid_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.68 GiB (GPU 0; 11.90 GiB total capacity; 5.37 GiB already allocated; 1.32 GiB free; 5.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"/home/niranjan/Projects/Fetch/curious_dog_isaac/legged_gym/resources/room_layout.png\",0)\n",
    "image_size = 1000\n",
    "dx = image_size//20\n",
    "image = cv2.resize(image,(image_size,image_size)).astype(np.float32)\n",
    "num_envs = 360\n",
    "image_batch = torch.tensor(image, device=torch.device(\"cuda\")).repeat(num_envs,1,1).view(num_envs,1,1000,1000)\n",
    "theta = torch.rand(num_envs)*np.pi/4\n",
    "agent_pos_x = torch.rand(num_envs)*5 - 3\n",
    "agent_pos_y = torch.rand(num_envs)*5 - 2.5\n",
    "rot_mat = get_batch_rot_mat(theta).to(torch.device(\"cuda\"))\n",
    "for i in range(num_envs):\n",
    "    image_batch[i,0,int(agent_pos_x[i]*dx+image_size//2)-10:int(agent_pos_x[i]*dx+image_size//2)+10,\n",
    "                    int(agent_pos_y[i]*dx+image_size//2)-10:int(agent_pos_y[i]*dx+image_size//2)+10] = 255\n",
    "rot_mat[:,0,-1] = agent_pos_y*dx/image_size*2\n",
    "rot_mat[:,1,-1] = agent_pos_x*dx/image_size*2\n",
    "grid = F.affine_grid(rot_mat, image_batch.size())\n",
    "x = F.grid_sample(image_batch, grid).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(x[1,0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[3,0,400:600,400:600])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('rlgpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d9b4ce1d3ef76299c1eaa1b1a2c1d596ae00bd5362c072b0e5079c0fc3c49af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
